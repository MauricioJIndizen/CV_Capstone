{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACE AND EYE RECOGNITION USING VIOLA&JONES (HAAR CASCADE CLASSIFIER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook includes a code for face and eye recognition from our webcam images using Haar Cascade classifier. Once eyes are extracted from the original image, that images is cropped and used to predict, using our model trainned with our dataset, if the eyes are opened or closed.\n",
    "\n",
    "Haar Cascade have some issues detecting closed eyes as eyes, also it can detect noise holes, chin or mouth as eyes and our model also have some problems classifing this closed eyes as closed, but its an initial code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object Detection using Haar feature-based cascade classifiers is an effective object detection method proposed by Paul Viola and Michael Jones in their paper, \"Rapid Object Detection using a Boosted Cascade of Simple Features\" in 2001. It is a machine learning based approach where a cascade function is trained from a lot of positive and negative images. It is then used to detect objects in other images.\n",
    "\n",
    "Initially, the algorithm needs a lot of positive images (images of faces) and negative images (images without faces) to train the classifier. Then we need to extract features from it. For this, Haar features shown in the below image are used. They are just like our convolutional kernel. Each feature is a single value obtained by subtracting sum of pixels under the white rectangle from sum of pixels under the black rectangle.\n",
    "\n",
    "<img src=\"notebook_images/haar.jpeg\">\n",
    "\n",
    "OpenCV library includes some models already trained for many object detections, for our case there are models for face and eye detection, that can be easily used with Python.\n",
    "\n",
    "This is a old model that gives quite good results and can be used at real-time applications, but Haar cascades are notoriously prone to false-positives â€” the Viola-Jones algorithm can easily report a face in an image when no face is present.\n",
    "\n",
    "More modern and accurate models must be taken into account, as this method has now been far surpassed by other methods, such as using Histogram of Oriented Gradients (HOG) + Linear SVM and deep learning (CNN, YOLO). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to C:\\Users\\guill/.cache\\torch\\hub\\master.zip\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m torchvision>=0.8.1 not found and is required by YOLOv5, attempting auto-update...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Command 'pip install 'torchvision>=0.8.1' ' returned non-zero exit status 1.\n",
      "YOLOv5  2022-5-26 Python-3.8.5 torch-1.10.2+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error opening video stream or file\n",
      "Error opening video stream or file\n",
      "Error opening video stream or file\n",
      "Error opening video stream or file\n",
      "Error opening video stream or file\n",
      "Error opening video stream or file\n",
      "Error opening video stream or file\n",
      "Error opening video stream or file\n",
      "Error opening video stream or file\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\guill\\Desktop\\INDIZEN\\Capstone\\Repositorio\\CV_Capstone\\eye classifier notebooks\\videos\"\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='model/yolo.pt', force_reload=True)\n",
    "clf_model = load_model('model/eye_classifier1_v4.h5')\n",
    "for file in os.listdir(path):\n",
    "    cap = cv2.VideoCapture(file)\n",
    "    frames = 120\n",
    "    if (cap.isOpened()== False):\n",
    "        print(\"Error opening video stream or file\")\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        # if frame is read correctly ret is True\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "        if frames == 120:\n",
    "            start = time.time()\n",
    "        elif frames == 0:\n",
    "            frames = 121\n",
    "            end = time.time()\n",
    "            seconds = end - start\n",
    "            print (\"Time taken : {0} seconds\".format(seconds))\n",
    "            # Calculate frames per second\n",
    "            fps  = 120 / seconds\n",
    "            print(\"Estimated frames per second : {0}\".format(fps))\n",
    "        result = model(frame)        \n",
    "        df = result.pandas().xyxy[0]\n",
    "        if len(df)>2:\n",
    "            df2 = df\n",
    "        for j in range(len(df)):\n",
    "            if float(df[\"confidence\"][j]) > 0.5:\n",
    "                xmin = int(df[\"xmin\"][j])\n",
    "                xmax = int(df[\"xmax\"][j])\n",
    "                ymin = int(df[\"ymin\"][j])\n",
    "                ymax = int(df[\"ymax\"][j])\n",
    "                eye_image = frame[ymin:ymax, xmin:xmax]\n",
    "                eye_scaled = resize(eye_image, (80, 80), preserve_range=True).astype(np.uint8)\n",
    "                eye_scaled_norm = eye_scaled.astype(\"float32\") / 255\n",
    "                out_probabilities = clf_model.predict(np.reshape(eye_scaled_norm,(1,80,80,3)))\n",
    "                result = \"OPENED\" + str(out_probabilities[0][0]) if out_probabilities[0][0] > 0.5 else \"CLOSED \" + str(out_probabilities[0][0])\n",
    "                result = \"OPENED\" if out_probabilities[0][0] > 0.5 else \"CLOSED \"\n",
    "                text_x = int(xmin)\n",
    "                text_y = int(ymin-20)\n",
    "                #DRAW TEXT OVER EYES\n",
    "                cv2.rectangle(frame,(xmin,ymin),(xmax,ymax),color=(255, 0, 0), thickness=3)\n",
    "                cv2.putText(frame, result, (text_x, text_y), cv2.FONT_HERSHEY_PLAIN, 1, (255,0,0), 1, cv2.LINE_AA)\n",
    "        cv2.imshow('frame', frame)\n",
    "        frames = frames - 1\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to C:\\Users\\guill/.cache\\torch\\hub\\master.zip\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m torchvision>=0.8.1 not found and is required by YOLOv5, attempting auto-update...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Command 'pip install 'torchvision>=0.8.1' ' returned non-zero exit status 1.\n",
      "YOLOv5  2022-5-25 Python-3.8.5 torch-1.10.2+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken : 34.466389656066895 seconds\n",
      "Estimated frames per second : 3.4816527404655853\n"
     ]
    }
   ],
   "source": [
    "file = \"prueba_mauricio2.mp4\"\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='model/yolo.pt', force_reload=True)\n",
    "clf_model = load_model('model/eye_classifier1_v4.h5')\n",
    "cap = cv2.VideoCapture(file)\n",
    "frames = 120\n",
    "if (cap.isOpened()== False):\n",
    "    print(\"Error opening video stream or file\")\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    if frames == 120:\n",
    "        start = time.time()\n",
    "    elif frames == 0:\n",
    "        frames = 121\n",
    "        end = time.time()\n",
    "        seconds = end - start\n",
    "        print (\"Time taken : {0} seconds\".format(seconds))\n",
    "        # Calculate frames per second\n",
    "        fps  = 120 / seconds\n",
    "        print(\"Estimated frames per second : {0}\".format(fps))\n",
    "    result = model(frame)        \n",
    "    df = result.pandas().xyxy[0]\n",
    "    if len(df)>2:\n",
    "        df2 = df\n",
    "    for j in range(len(df)):\n",
    "        if float(df[\"confidence\"][j]) > 0.5:\n",
    "            xmin = int(df[\"xmin\"][j])\n",
    "            xmax = int(df[\"xmax\"][j])\n",
    "            ymin = int(df[\"ymin\"][j])\n",
    "            ymax = int(df[\"ymax\"][j])\n",
    "            eye_image = frame[ymin:ymax, xmin:xmax]\n",
    "            eye_scaled = resize(eye_image, (80, 80), preserve_range=True).astype(np.uint8)\n",
    "            eye_scaled_norm = eye_scaled.astype(\"float32\") / 255\n",
    "            gray = cv2.cvtColor(eye_scaled_norm, cv2.COLOR_BGR2GRAY)\n",
    "            out_probabilities = clf_model.predict(np.reshape(gray,(1,80,80,1)))\n",
    "            result = \"OPENED\" + str(out_probabilities[0][0]) if out_probabilities[0][0] > 0.5 else \"CLOSED \" + str(out_probabilities[0][0])\n",
    "            result = \"OPENED\" if out_probabilities[0][0] > 0.5 else \"CLOSED \"\n",
    "            text_x = int(xmin)\n",
    "            text_y = int(ymin-20)\n",
    "            #DRAW TEXT OVER EYES\n",
    "            cv2.rectangle(frame,(xmin,ymin),(xmax,ymax),color=(255, 0, 0), thickness=3)\n",
    "            cv2.putText(frame, result, (text_x, text_y), cv2.FONT_HERSHEY_PLAIN, 1, (255,0,0), 1, cv2.LINE_AA)\n",
    "    cv2.imshow('frame', frame)\n",
    "    frames = frames - 1\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
